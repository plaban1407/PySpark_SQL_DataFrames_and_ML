{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4d51b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Spark from Apache Foundation\n",
    "# Extract and rename to 'Spark' and place it to the home directory\n",
    "# Open terminal \n",
    "# pwd -> check home directory\n",
    "# cd Spark\n",
    "# ls\n",
    "# cd bin\n",
    "# cd -> back to the home directory\n",
    "# nano .bash_profile\n",
    "\n",
    "#export SPARK_HOME=\"/home/pla/spark\"\n",
    "#export PATH=$SPARK_HOME/bin:$PATH\n",
    "#export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "#export PYSPARK_DRIVER_PYTHON_OPTS='notebook'\n",
    "\n",
    "# save the bash file\n",
    "\n",
    "# back in the terminal\n",
    "# source .bash_profile -> to run the bash file\n",
    "\n",
    "# install PySpark\n",
    "# pip install pyspark\n",
    "\n",
    "# python3 -m pip install jupyter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91038184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd24ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/24 21:27:34 WARN Utils: Your hostname, pla-M14xR1 resolves to a loopback address: 127.0.1.1; using 192.168.0.160 instead (on interface wlp13s0)\n",
      "21/08/24 21:27:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/08/24 21:27:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"SparkByExamples.com\").getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47f916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3f4537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.160:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6b77a559a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3089604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1040122",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_path + \"/location_temp.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "358ef777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/location_temp.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705dcf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.format(\"csv\").option(\"header\",\"true\").load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf174fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(event_date='03/04/2019 19:48:06', location_id='loc0', temp_celcius='29'),\n",
       " Row(event_date='03/04/2019 19:53:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 19:58:06', location_id='loc0', temp_celcius='28'),\n",
       " Row(event_date='03/04/2019 20:03:06', location_id='loc0', temp_celcius='30'),\n",
       " Row(event_date='03/04/2019 20:08:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 20:13:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 20:18:06', location_id='loc0', temp_celcius='27'),\n",
       " Row(event_date='03/04/2019 20:23:06', location_id='loc0', temp_celcius='29'),\n",
       " Row(event_date='03/04/2019 20:28:06', location_id='loc0', temp_celcius='32'),\n",
       " Row(event_date='03/04/2019 20:33:06', location_id='loc0', temp_celcius='35')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7877d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445f6363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dee734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "file_path_no_header = data_path + \"/utilization.csv\"\n",
    "df2 = spark.read.format(\"csv\").option(\"header\",\"false\").option(\"inferSchema\",\"true\").load(file_path_no_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52cd185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "721e4acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='03/05/2019 08:06:14', _c1=100, _c2=0.57, _c3=0.51, _c4=47),\n",
       " Row(_c0='03/05/2019 08:11:14', _c1=100, _c2=0.47, _c3=0.62, _c4=43),\n",
       " Row(_c0='03/05/2019 08:16:14', _c1=100, _c2=0.56, _c3=0.57, _c4=62),\n",
       " Row(_c0='03/05/2019 08:21:14', _c1=100, _c2=0.57, _c3=0.56, _c4=50),\n",
       " Row(_c0='03/05/2019 08:26:14', _c1=100, _c2=0.35, _c3=0.46, _c4=43),\n",
       " Row(_c0='03/05/2019 08:31:14', _c1=100, _c2=0.41, _c3=0.58, _c4=48),\n",
       " Row(_c0='03/05/2019 08:36:14', _c1=100, _c2=0.57, _c3=0.35, _c4=58),\n",
       " Row(_c0='03/05/2019 08:41:14', _c1=100, _c2=0.41, _c3=0.4, _c4=58),\n",
       " Row(_c0='03/05/2019 08:46:14', _c1=100, _c2=0.53, _c3=0.35, _c4=62),\n",
       " Row(_c0='03/05/2019 08:51:14', _c1=100, _c2=0.51, _c3=0.6, _c4=45)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "194d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumnRenamed(\"_c0\", \"event_datetime\") \\\n",
    "         .withColumnRenamed(\"_c1\", \"server_id\") \\\n",
    "         .withColumnRenamed(\"_c2\",\"cpu_utilization\") \\\n",
    "         .withColumnRenamed(\"_c3\",\"free_memory\") \\\n",
    "         .withColumnRenamed(\"_c4\", \"session_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676f908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(event_datetime='03/05/2019 08:06:14', server_id=100, cpu_utilization=0.57, free_memory=0.51, session_count=47),\n",
       " Row(event_datetime='03/05/2019 08:11:14', server_id=100, cpu_utilization=0.47, free_memory=0.62, session_count=43),\n",
       " Row(event_datetime='03/05/2019 08:16:14', server_id=100, cpu_utilization=0.56, free_memory=0.57, session_count=62),\n",
       " Row(event_datetime='03/05/2019 08:21:14', server_id=100, cpu_utilization=0.57, free_memory=0.56, session_count=50),\n",
       " Row(event_datetime='03/05/2019 08:26:14', server_id=100, cpu_utilization=0.35, free_memory=0.46, session_count=43),\n",
       " Row(event_datetime='03/05/2019 08:31:14', server_id=100, cpu_utilization=0.41, free_memory=0.58, session_count=48),\n",
       " Row(event_datetime='03/05/2019 08:36:14', server_id=100, cpu_utilization=0.57, free_memory=0.35, session_count=58),\n",
       " Row(event_datetime='03/05/2019 08:41:14', server_id=100, cpu_utilization=0.41, free_memory=0.4, session_count=58),\n",
       " Row(event_datetime='03/05/2019 08:46:14', server_id=100, cpu_utilization=0.53, free_memory=0.35, session_count=62),\n",
       " Row(event_datetime='03/05/2019 08:51:14', server_id=100, cpu_utilization=0.51, free_memory=0.6, session_count=45)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8462b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|     event_datetime|server_id|cpu_utilization|free_memory|session_count|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "|03/05/2019 08:06:14|      100|           0.57|       0.51|           47|\n",
      "|03/05/2019 08:11:14|      100|           0.47|       0.62|           43|\n",
      "|03/05/2019 08:16:14|      100|           0.56|       0.57|           62|\n",
      "|03/05/2019 08:21:14|      100|           0.57|       0.56|           50|\n",
      "|03/05/2019 08:26:14|      100|           0.35|       0.46|           43|\n",
      "|03/05/2019 08:31:14|      100|           0.41|       0.58|           48|\n",
      "|03/05/2019 08:36:14|      100|           0.57|       0.35|           58|\n",
      "|03/05/2019 08:41:14|      100|           0.41|        0.4|           58|\n",
      "|03/05/2019 08:46:14|      100|           0.53|       0.35|           62|\n",
      "|03/05/2019 08:51:14|      100|           0.51|        0.6|           45|\n",
      "|03/05/2019 08:56:14|      100|           0.32|       0.37|           47|\n",
      "|03/05/2019 09:01:14|      100|           0.62|       0.59|           60|\n",
      "|03/05/2019 09:06:14|      100|           0.66|       0.72|           57|\n",
      "|03/05/2019 09:11:14|      100|           0.54|       0.54|           44|\n",
      "|03/05/2019 09:16:14|      100|           0.29|        0.4|           47|\n",
      "|03/05/2019 09:21:14|      100|           0.43|       0.68|           66|\n",
      "|03/05/2019 09:26:14|      100|           0.49|       0.66|           65|\n",
      "|03/05/2019 09:31:14|      100|           0.64|       0.55|           66|\n",
      "|03/05/2019 09:36:14|      100|           0.42|        0.6|           42|\n",
      "|03/05/2019 09:41:14|      100|           0.55|       0.59|           63|\n",
      "+-------------------+---------+---------------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036a85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd510eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8430d79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "json_df1_path = data_path + \"/utlization.json\"\n",
    "df1 = spark.read.format(\"json\").load(json_df1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65241d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991b8b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f01fb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1abd31e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be0b9bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpu_utilization',\n",
       " 'event_datetime',\n",
       " 'free_memory',\n",
       " 'server_id',\n",
       " 'session_count']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aeffa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to work with subset of the data\n",
    "\n",
    "df1_sample = df1.sample(False, fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df31892d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49759"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f012586a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|\n",
      "|           0.56|03/05/2019 10:26:14|       0.69|      100|           44|\n",
      "|           0.66|03/05/2019 11:31:14|        0.6|      100|           56|\n",
      "|           0.27|03/05/2019 12:11:14|       0.65|      100|           69|\n",
      "|            0.5|03/05/2019 12:16:14|        0.5|      100|           51|\n",
      "|           0.35|03/05/2019 12:31:14|       0.42|      100|           71|\n",
      "|           0.48|03/05/2019 12:56:14|       0.38|      100|           44|\n",
      "|           0.29|03/05/2019 13:11:14|       0.48|      100|           48|\n",
      "|           0.41|03/05/2019 13:51:14|       0.59|      100|           67|\n",
      "|           0.33|03/05/2019 14:06:14|       0.53|      100|           44|\n",
      "|           0.45|03/05/2019 14:11:14|       0.64|      100|           67|\n",
      "|           0.56|03/05/2019 14:56:14|       0.48|      100|           39|\n",
      "|           0.39|03/05/2019 15:01:14|       0.52|      100|           48|\n",
      "|           0.58|03/05/2019 15:11:14|       0.54|      100|           49|\n",
      "|           0.59|03/05/2019 15:36:14|       0.37|      100|           70|\n",
      "|           0.63|03/05/2019 15:56:14|       0.42|      100|           61|\n",
      "|           0.33|03/05/2019 16:16:14|       0.49|      100|           52|\n",
      "|           0.56|03/05/2019 16:41:14|       0.59|      100|           65|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe0ba07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_sort = df1_sample.sort('event_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc84e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.86|03/05/2019 08:06:16|       0.09|      101|           93|\n",
      "|           0.84|03/05/2019 08:06:21|       0.36|      104|           94|\n",
      "|            0.4|03/05/2019 08:06:24|       0.39|      106|           43|\n",
      "|           0.62|03/05/2019 08:06:28|       0.41|      108|           86|\n",
      "|           0.52|03/05/2019 08:07:00|       0.49|      127|           75|\n",
      "|           0.61|03/05/2019 08:07:25|       0.15|      140|           69|\n",
      "|           0.61|03/05/2019 08:12:01|       0.29|      128|           59|\n",
      "|           0.74|03/05/2019 08:12:03|       0.62|      129|           81|\n",
      "|           0.34|03/05/2019 08:12:13|       0.64|      134|           73|\n",
      "|           0.71|03/05/2019 08:12:19|       0.45|      137|           70|\n",
      "|           0.74|03/05/2019 08:12:29|       0.23|      142|           79|\n",
      "|           0.97|03/05/2019 08:12:35|       0.27|      145|          100|\n",
      "|           0.54|03/05/2019 08:17:06|       0.28|      130|           55|\n",
      "|           0.48|03/05/2019 08:17:25|       0.36|      140|           62|\n",
      "|           0.51|03/05/2019 08:17:31|       0.44|      143|           45|\n",
      "|           0.88|03/05/2019 08:17:35|       0.22|      145|           85|\n",
      "|           0.74|03/05/2019 08:21:29|       0.52|      109|           64|\n",
      "|            0.7|03/05/2019 08:21:36|       0.11|      113|           72|\n",
      "|            0.7|03/05/2019 08:21:51|       0.33|      122|           86|\n",
      "|           0.69|03/05/2019 08:22:09|       0.59|      132|           71|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1_sort.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "750e9647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = data_path + \"/location_temp.csv\"\n",
    "df1 = spark.read.format(\"csv\").option(\"header\",\"true\").load(file_path)\n",
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b4f360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter \n",
    "\n",
    "df1.filter(df1[\"location_id\"]==\"loc0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5860ce1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"]==\"loc0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed622bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"]==\"loc1\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61ec5085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.filter(df1[\"location_id\"]==\"loc0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f84b5672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 31:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "[Stage 31:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|     loc196| 1000|\n",
      "|     loc226| 1000|\n",
      "|     loc463| 1000|\n",
      "|     loc150| 1000|\n",
      "|     loc292| 1000|\n",
      "|     loc311| 1000|\n",
      "|      loc22| 1000|\n",
      "|     loc351| 1000|\n",
      "|     loc370| 1000|\n",
      "|     loc419| 1000|\n",
      "|      loc31| 1000|\n",
      "|     loc305| 1000|\n",
      "|      loc82| 1000|\n",
      "|      loc90| 1000|\n",
      "|     loc118| 1000|\n",
      "|     loc195| 1000|\n",
      "|     loc208| 1000|\n",
      "|      loc39| 1000|\n",
      "|      loc75| 1000|\n",
      "|     loc228| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "149ce9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 37:=============================>                            (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.orderBy(\"location_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e1afcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 38:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|     loc196|           29.225|\n",
      "|     loc226|           25.306|\n",
      "|     loc463|           23.317|\n",
      "|     loc150|           32.188|\n",
      "|     loc292|           29.159|\n",
      "|     loc311|           24.308|\n",
      "|      loc22|           28.251|\n",
      "|     loc351|           28.194|\n",
      "|     loc370|            29.14|\n",
      "|     loc419|           29.141|\n",
      "|      loc31|           25.196|\n",
      "|     loc305|           27.314|\n",
      "|      loc82|           27.355|\n",
      "|      loc90|           23.216|\n",
      "|     loc118|           24.219|\n",
      "|     loc195|            27.25|\n",
      "|     loc208|           26.206|\n",
      "|      loc39|           25.199|\n",
      "|      loc75|           23.209|\n",
      "|     loc228|           27.295|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 38:===========================================>              (3 + 1) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").agg({'temp_celcius':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80e99662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 44:>                                                         (0 + 4) / 4]\r",
      "\r",
      "[Stage 44:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|max(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|     loc196|               36|\n",
      "|     loc226|               32|\n",
      "|     loc463|               30|\n",
      "|     loc150|               39|\n",
      "|     loc292|               36|\n",
      "|     loc311|               31|\n",
      "|      loc22|               35|\n",
      "|     loc351|               35|\n",
      "|     loc370|               36|\n",
      "|     loc419|               36|\n",
      "|     loc305|               34|\n",
      "|      loc31|               32|\n",
      "|     loc118|               31|\n",
      "|     loc195|               34|\n",
      "|     loc208|               33|\n",
      "|      loc82|               34|\n",
      "|      loc90|               30|\n",
      "|     loc228|               34|\n",
      "|      loc39|               32|\n",
      "|      loc75|               30|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").agg({'temp_celcius':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14b17364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b891d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c18b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_sample = df1.sample(fraction=0.1, withReplacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a73f857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49847"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b3086fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 55:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "[Stage 55:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|     loc196|29.306122448979593|\n",
      "|     loc226|25.220183486238533|\n",
      "|     loc463|23.224719101123597|\n",
      "|     loc150| 32.37373737373738|\n",
      "|     loc292|28.926315789473684|\n",
      "|     loc311|24.454545454545453|\n",
      "|      loc22|             28.35|\n",
      "|     loc351|28.865168539325843|\n",
      "|     loc370|            29.232|\n",
      "|     loc419| 29.22680412371134|\n",
      "|      loc31| 25.06741573033708|\n",
      "|     loc305|27.423076923076923|\n",
      "|      loc82|27.296296296296298|\n",
      "|      loc90|              23.5|\n",
      "|     loc118|23.928571428571427|\n",
      "|     loc195|27.376344086021504|\n",
      "|     loc208|26.513761467889907|\n",
      "|      loc39|25.224489795918366|\n",
      "|      loc75|23.473118279569892|\n",
      "|     loc228|27.615384615384617|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "df1_sample.groupBy(\"location_id\").agg({'temp_celcius':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b36e6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:================================================>     (180 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|location_id| avg(temp_celcius)|\n",
      "+-----------+------------------+\n",
      "|       loc0| 29.43103448275862|\n",
      "|       loc1|  28.2972972972973|\n",
      "|      loc10| 25.08080808080808|\n",
      "|     loc100|             27.14|\n",
      "|     loc101|25.367816091954023|\n",
      "|     loc102|30.427272727272726|\n",
      "|     loc103|25.451923076923077|\n",
      "|     loc104|26.056603773584907|\n",
      "|     loc105|26.071428571428573|\n",
      "|     loc106|             27.03|\n",
      "+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1_sample.groupBy(\"location_id\").agg({'temp_celcius':'mean'}).orderBy(\"location_id\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1da1d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:====================================>                 (137 + 6) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|       loc0|           29.176|\n",
      "|       loc1|           28.246|\n",
      "|      loc10|           25.337|\n",
      "|     loc100|           27.297|\n",
      "|     loc101|           25.317|\n",
      "|     loc102|           30.327|\n",
      "|     loc103|           25.341|\n",
      "|     loc104|           26.204|\n",
      "|     loc105|           26.217|\n",
      "|     loc106|           27.201|\n",
      "+-----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 64:===============================================>      (175 + 5) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"location_id\").agg({'temp_celcius':'mean'}).orderBy(\"location_id\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "452dd254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Save data from DataFrame\n",
    "\n",
    "df1.write.csv('df1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bc30f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'CH 03'    PySpark_dataframes_and_analysis.ipynb\r\n",
      "'CH 04'   'Spark Mac Linux Export Environment Variables'\r\n",
      "'CH 05'    spark-warehouse\r\n",
      " Data\t  'Spark Windows Instructions'\r\n",
      " df1.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d348659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-ebda42ac-4372-4bad-a45f-a0f33c3bf56c-c000.csv\r\n",
      "part-00001-ebda42ac-4372-4bad-a45f-a0f33c3bf56c-c000.csv\r\n",
      "part-00002-ebda42ac-4372-4bad-a45f-a0f33c3bf56c-c000.csv\r\n",
      "part-00003-ebda42ac-4372-4bad-a45f-a0f33c3bf56c-c000.csv\r\n",
      "_SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "!ls df1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "297537f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'df1.csv/part-00000-09a7b0f5-c02a-4365-a7d1-d1f3fa9aeb27-c000.csv' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! head df1.csv/part-00000-09a7b0f5-c02a-4365-a7d1-d1f3fa9aeb27-c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1be64e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.write.json('df1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "946466a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-dcc61fa3-cf5b-4e6a-b644-e3651db2579a-c000.json\r\n",
      "part-00001-dcc61fa3-cf5b-4e6a-b644-e3651db2579a-c000.json\r\n",
      "part-00002-dcc61fa3-cf5b-4e6a-b644-e3651db2579a-c000.json\r\n",
      "part-00003-dcc61fa3-cf5b-4e6a-b644-e3651db2579a-c000.json\r\n",
      "_SUCCESS\r\n"
     ]
    }
   ],
   "source": [
    "! ls df1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdb84cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'df1.json/part-00000-66bf3f84-7a52-4e30-a12f-90cdf6f0896f-c000.json' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! head df1.json/part-00000-66bf3f84-7a52-4e30-a12f-90cdf6f0896f-c000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f519649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark SQL -> SQL for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4fc9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.appName(\"Spark SQL Query DataFrames\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3b678b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df_path = data_path + \"/utlization.json\"\n",
    "df = spark.read.format(\"json\").load(json_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be5b8551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c8cc4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6959f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "023206a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql(\"SELECT * FROM utilization LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bb46146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef2bcb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8fdbba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id, session_count FROM utilization LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e9affd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      100|           47|\n",
      "|      100|           43|\n",
      "|      100|           62|\n",
      "|      100|           50|\n",
      "|      100|           43|\n",
      "|      100|           48|\n",
      "|      100|           58|\n",
      "|      100|           58|\n",
      "|      100|           62|\n",
      "|      100|           45|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "140722a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id AS sid, session_count AS sc FROM utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5664033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|sid| sc|\n",
      "+---+---+\n",
      "|100| 47|\n",
      "|100| 43|\n",
      "|100| 62|\n",
      "|100| 50|\n",
      "|100| 43|\n",
      "|100| 48|\n",
      "|100| 58|\n",
      "|100| 58|\n",
      "|100| 62|\n",
      "|100| 45|\n",
      "|100| 47|\n",
      "|100| 60|\n",
      "|100| 57|\n",
      "|100| 44|\n",
      "|100| 47|\n",
      "|100| 66|\n",
      "|100| 65|\n",
      "|100| 66|\n",
      "|100| 42|\n",
      "|100| 63|\n",
      "+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "846a5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering DataFrame with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d3cd565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa017d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql(\"SELECT * FROM utilization where server_id = 120\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c848762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.66|03/05/2019 08:06:48|       0.31|      120|           54|\n",
      "|           0.58|03/05/2019 08:11:48|       0.38|      120|           64|\n",
      "|           0.55|03/05/2019 08:16:48|       0.61|      120|           54|\n",
      "|            0.7|03/05/2019 08:21:48|       0.35|      120|           80|\n",
      "|            0.6|03/05/2019 08:26:48|       0.39|      120|           71|\n",
      "|           0.53|03/05/2019 08:31:48|       0.35|      120|           49|\n",
      "|           0.73|03/05/2019 08:36:48|       0.42|      120|           73|\n",
      "|           0.41|03/05/2019 08:41:48|        0.6|      120|           72|\n",
      "|           0.62|03/05/2019 08:46:48|       0.57|      120|           57|\n",
      "|           0.67|03/05/2019 08:51:48|       0.44|      120|           78|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "666f210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ea83906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id, session_count FROM utilization where session_count > 70\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84c36207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           72|\n",
      "|      100|           72|\n",
      "|      100|           71|\n",
      "|      100|           71|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "efe61d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239659"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3e6fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id, session_count FROM utilization WHERE session_count > 70 AND server_id=120\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "031cc123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2733"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b4ae032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           71|\n",
      "|      120|           73|\n",
      "|      120|           72|\n",
      "|      120|           78|\n",
      "|      120|           73|\n",
      "|      120|           78|\n",
      "|      120|           73|\n",
      "|      120|           74|\n",
      "|      120|           78|\n",
      "|      120|           75|\n",
      "|      120|           75|\n",
      "|      120|           73|\n",
      "|      120|           79|\n",
      "|      120|           72|\n",
      "|      120|           77|\n",
      "|      120|           75|\n",
      "|      120|           72|\n",
      "|      120|           79|\n",
      "|      120|           75|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f042c860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id, session_count \\\n",
    "                   FROM utilization \\\n",
    "                   where session_count > 70 and server_id = 120 \\\n",
    "                   ORDER BY session_count DESC\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3b40a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating Data with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0de77a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "json_df2_path = data_path + \"/utlization.json\"\n",
    "df = spark.read.format(\"json\").load(json_df1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4c8b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa6a6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "69866548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  500000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_count = spark.sql(\"SELECT count(*) FROM utilization\")\n",
    "df_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c84a9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  239659|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 94:==============>                                           (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"SELECT count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "171d41ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      112|    7425|\n",
      "|      113|    9418|\n",
      "|      130|    2891|\n",
      "|      126|    6365|\n",
      "|      149|    8288|\n",
      "|      110|    2826|\n",
      "|      136|    4316|\n",
      "|      144|    6220|\n",
      "|      116|    1167|\n",
      "|      145|    9304|\n",
      "|      143|     144|\n",
      "|      107|    5646|\n",
      "|      146|    7072|\n",
      "|      103|    8744|\n",
      "|      139|    7383|\n",
      "|      114|    2128|\n",
      "|      115|    5284|\n",
      "|      104|    7366|\n",
      "|      120|    2733|\n",
      "|      128|    3719|\n",
      "+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id, count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7a132fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 104:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      101|    9808|\n",
      "|      113|    9418|\n",
      "|      145|    9304|\n",
      "|      103|    8744|\n",
      "|      102|    8586|\n",
      "|      133|    8583|\n",
      "|      108|    8375|\n",
      "|      149|    8288|\n",
      "|      137|    8248|\n",
      "|      148|    8027|\n",
      "|      123|    7918|\n",
      "|      118|    7913|\n",
      "|      112|    7425|\n",
      "|      139|    7383|\n",
      "|      104|    7366|\n",
      "|      142|    7084|\n",
      "|      121|    7084|\n",
      "|      146|    7072|\n",
      "|      126|    6365|\n",
      "|      144|    6220|\n",
      "+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 105:==========================================>          (159 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id, count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id \\\n",
    "                    ORDER BY count(*) DESC\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce4616ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:===================================================> (195 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------------------------+------------------+\n",
      "|server_id|min(session_count)|round(avg(session_count), 2)|max(session_count)|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "|      101|                71|                       87.67|               105|\n",
      "|      113|                71|                       86.96|               103|\n",
      "|      145|                71|                       86.98|               103|\n",
      "|      103|                71|                       85.76|               101|\n",
      "|      102|                71|                       85.71|               101|\n",
      "|      133|                71|                       85.47|               100|\n",
      "|      108|                71|                       85.12|               100|\n",
      "|      149|                71|                       84.96|                99|\n",
      "|      137|                71|                       85.01|                99|\n",
      "|      148|                71|                        84.7|                99|\n",
      "|      123|                71|                       84.53|                98|\n",
      "|      118|                71|                       84.66|                98|\n",
      "|      112|                71|                       83.55|                97|\n",
      "|      139|                71|                       83.33|                96|\n",
      "|      104|                71|                       83.35|                96|\n",
      "|      142|                71|                        82.9|                95|\n",
      "|      121|                71|                       82.89|                95|\n",
      "|      146|                71|                       82.95|                95|\n",
      "|      126|                71|                       81.56|                93|\n",
      "|      144|                71|                       81.38|                92|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"SELECT server_id, min(session_count), round(avg(session_count),2), max(session_count) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70 \\\n",
    "                    GROUP BY server_id \\\n",
    "                    ORDER BY count(*) DESC\")\n",
    "df_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38e237f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7423dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b86d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32fa3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df_server_path = data_path + \"/server_name.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c7642ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|server_id|server_name|\n",
      "+---------+-----------+\n",
      "|      100| 100 Server|\n",
      "|      101| 101 Server|\n",
      "|      102| 102 Server|\n",
      "|      103| 103 Server|\n",
      "|      104| 104 Server|\n",
      "|      105| 105 Server|\n",
      "|      106| 106 Server|\n",
      "|      107| 107 Server|\n",
      "|      108| 108 Server|\n",
      "|      109| 109 Server|\n",
      "|      110| 110 Server|\n",
      "|      111| 111 Server|\n",
      "|      112| 112 Server|\n",
      "|      113| 113 Server|\n",
      "|      114| 114 Server|\n",
      "|      115| 115 Server|\n",
      "|      116| 116 Server|\n",
      "|      117| 117 Server|\n",
      "|      118| 118 Server|\n",
      "|      119| 119 Server|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_server = spark.read.csv(csv_df_server_path, header=True)\n",
    "df_server.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "635baa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_server.createOrReplaceTempView(\"server_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "93eb5497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 111:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|server_id|\n",
      "+---------+\n",
      "|      100|\n",
      "|      101|\n",
      "|      102|\n",
      "|      103|\n",
      "|      104|\n",
      "|      105|\n",
      "|      106|\n",
      "|      107|\n",
      "|      108|\n",
      "|      109|\n",
      "|      110|\n",
      "|      111|\n",
      "|      112|\n",
      "|      113|\n",
      "|      114|\n",
      "|      115|\n",
      "|      116|\n",
      "|      117|\n",
      "|      118|\n",
      "|      119|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_count = spark.sql(\"SELECT DISTINCT server_id FROM utilization ORDER BY server_id\")\n",
    "df_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4aa70b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|min(server_id)|max(server_id)|\n",
      "+--------------+--------------+\n",
      "|           100|           149|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT min(server_id), max(server_id) FROM utilization\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c662847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining DataFrames with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ffb6c74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+\n",
      "|server_id|server_name|session_count|\n",
      "+---------+-----------+-------------+\n",
      "|      100| 100 Server|           47|\n",
      "|      100| 100 Server|           43|\n",
      "|      100| 100 Server|           62|\n",
      "|      100| 100 Server|           50|\n",
      "|      100| 100 Server|           43|\n",
      "|      100| 100 Server|           48|\n",
      "|      100| 100 Server|           58|\n",
      "|      100| 100 Server|           58|\n",
      "|      100| 100 Server|           62|\n",
      "|      100| 100 Server|           45|\n",
      "|      100| 100 Server|           47|\n",
      "|      100| 100 Server|           60|\n",
      "|      100| 100 Server|           57|\n",
      "|      100| 100 Server|           44|\n",
      "|      100| 100 Server|           47|\n",
      "|      100| 100 Server|           66|\n",
      "|      100| 100 Server|           65|\n",
      "|      100| 100 Server|           66|\n",
      "|      100| 100 Server|           42|\n",
      "|      100| 100 Server|           63|\n",
      "+---------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql(\"SELECT u.server_id, sn.server_name, u.session_count \\\n",
    "                    from utilization u \\\n",
    "                    INNER JOIN server_name sn \\\n",
    "                    ON sn.server_id = u.server_id\")\n",
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4797e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87205d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69883e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15194aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "68534c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 117:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Duplicate data\n",
    "df_dup = sc.parallelize([Row(server_name='101 Server', cpu_utilization=85, session_count=80),\\\n",
    "                         Row(server_name='101 Server', cpu_utilization=80, session_count=90), \\\n",
    "                         Row(server_name='102 Server', cpu_utilization=85, session_count=80), \\\n",
    "                         Row(server_name='102 Server', cpu_utilization=85, session_count=80)]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1f5b17cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 101 Server|             85|           80|\n",
      "| 101 Server|             80|           90|\n",
      "| 102 Server|             85|           80|\n",
      "| 102 Server|             85|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aefab4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimated duplicates in DataFrames Rowwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b81eac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 101 Server|             85|           80|\n",
      "| 101 Server|             80|           90|\n",
      "| 102 Server|             85|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup.drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ad1eac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimated duplicates in DataFrames Columnwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ba4f8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 102 Server|             85|           80|\n",
      "| 101 Server|             85|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup.drop_duplicates(['server_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd2eee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with NA values in DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4972381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "09bc6daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.parallelize([Row(server_name='101 Server', cpu_utilization=85, session_count=80),\\\n",
    "                         Row(server_name='101 Server', cpu_utilization=80, session_count=90), \\\n",
    "                         Row(server_name='102 Server', cpu_utilization=85, session_count=40), \\\n",
    "                         Row(server_name='103 Server', cpu_utilization=70, session_count=80), \\\n",
    "                         Row(server_name='104 Server', cpu_utilization=60, session_count=80)]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dfd44885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 101 Server|             85|           80|\n",
      "| 101 Server|             80|           90|\n",
      "| 102 Server|             85|           40|\n",
      "| 103 Server|             70|           80|\n",
      "| 104 Server|             60|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2f2da991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na = df.withColumn('na_col', lit(None).cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d060a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "450bf3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_na.fillna('A').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5a45f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df_na.fillna('A').union(df_na)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "90ef3811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4aa67376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"na_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ccd347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM na_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0e8d64f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM na_table where na_col IS NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f09c8738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM na_table where na_col IS NOT NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9c32a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring data analysis with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4cf7f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring data analysis with spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4b5aaf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 160:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# json_df1_path = data_path + \"/utlization.json\"\n",
    "df_util = spark.read.format(\"json\").load(json_df1_path)\n",
    "df_util.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "47541032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.createOrReplaceGlobalTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a6e01a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "298b890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 164:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|    cpu_utilization|     event_datetime|        free_memory|         server_id|     session_count|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|             500000|             500000|             500000|            500000|            500000|\n",
      "|   mean| 0.6205177400000106|               null| 0.3791280999999971|             124.5|          69.59616|\n",
      "| stddev|0.15875173872912937|               null|0.15830931278376237|14.430884120552962|14.850676696352718|\n",
      "|    min|               0.22|03/05/2019 08:06:14|                0.0|               100|                32|\n",
      "|    max|                1.0|04/09/2019 01:22:46|               0.78|               149|               105|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_util.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5589431f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 166:>                                                        (0 + 4) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.47047715730807543"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.stat.corr('cpu_utilization','free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fb9c8484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 167:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.500832084887659"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.stat.corr('session_count','free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "972aec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 168:>                                                        (0 + 4) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+\n",
      "| server_id_freqItems|session_count_freqItems|\n",
      "+--------------------+-----------------------+\n",
      "|[146, 137, 101, 1...|   [92, 101, 83, 104...|\n",
      "+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.stat.freqItems(('server_id', 'session_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2a0b1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util_sample = df_util.sample(fraction=0.05, withReplacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "341de55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25005"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f71bfd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring data analysis with spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cab8853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------------+\n",
      "|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "|                0.22|                 1.0|    0.15875173872912937|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 171:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) FROM utilization').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dc8b8cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------------+\n",
      "|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "|                0.52|                0.92|    0.11528867845082576|\n",
      "|                0.58|                0.98|    0.11544345150353687|\n",
      "|                0.35|                0.75|    0.11568834774245991|\n",
      "|                0.48|                0.88|    0.11542612970702058|\n",
      "|                0.54|                0.94|    0.11543517500295467|\n",
      "|                0.35|                0.75|    0.11533251724450215|\n",
      "|                0.41|                 0.8|    0.11597405743182258|\n",
      "|                0.47|                0.87|    0.11478654960489501|\n",
      "|                0.22|                0.62|    0.11516031929842008|\n",
      "|                 0.3|                 0.7|    0.11506079722349302|\n",
      "|                0.58|                0.98|    0.11476448868786197|\n",
      "|                0.24|                0.64|    0.11579377614906383|\n",
      "|                0.26|                0.66|    0.11616596078044727|\n",
      "|                0.45|                0.85|    0.11597417369783877|\n",
      "|                 0.5|                 0.9|    0.11488129439634706|\n",
      "|                0.56|                0.96|    0.11617507884178278|\n",
      "|                0.51|                0.91|    0.11519660023052102|\n",
      "|                0.24|                0.64|     0.1155955860444133|\n",
      "|                0.33|                0.73|    0.11510268816097273|\n",
      "|                0.44|                0.84|    0.11569664615014985|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) \\\n",
    "           FROM utilization \\\n",
    "           GROUP BY server_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "28bbf2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|server_id|bucket|\n",
      "+---------+------+\n",
      "|      100|     5|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     5|\n",
      "|      100|     3|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "|      100|     5|\n",
      "|      100|     3|\n",
      "|      100|     6|\n",
      "|      100|     6|\n",
      "|      100|     5|\n",
      "|      100|     2|\n",
      "|      100|     4|\n",
      "|      100|     4|\n",
      "|      100|     6|\n",
      "|      100|     4|\n",
      "|      100|     5|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, FLOOR(cpu_utilization*100/10) bucket FROM utilization').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "374ad8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 182:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|count(1)|bucket|\n",
      "+--------+------+\n",
      "|   88242|     7|\n",
      "|  116725|     6|\n",
      "|   20207|     9|\n",
      "|  104910|     5|\n",
      "|      57|    10|\n",
      "|   37029|     3|\n",
      "|   56598|     8|\n",
      "|    8186|     2|\n",
      "|   68046|     4|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT count(*), FLOOR(cpu_utilization*100/10) bucket FROM utilization GROUP BY bucket').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ea740468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a24c943f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/utlization.json'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_df1_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f41b1907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util = spark.read.format(\"json\").load(json_df1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "199814c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3530fb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 193:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|server_id|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|      112|                0.52|                0.92|    0.11528867845082576|\n",
      "|      113|                0.58|                0.98|    0.11544345150353687|\n",
      "|      130|                0.35|                0.75|    0.11568834774245991|\n",
      "|      126|                0.48|                0.88|    0.11542612970702058|\n",
      "|      149|                0.54|                0.94|    0.11543517500295467|\n",
      "|      110|                0.35|                0.75|    0.11533251724450215|\n",
      "|      136|                0.41|                 0.8|    0.11597405743182258|\n",
      "|      144|                0.47|                0.87|    0.11478654960489501|\n",
      "|      119|                0.22|                0.62|    0.11516031929842008|\n",
      "|      116|                 0.3|                 0.7|    0.11506079722349302|\n",
      "|      145|                0.58|                0.98|    0.11476448868786197|\n",
      "|      124|                0.24|                0.64|    0.11579377614906383|\n",
      "|      143|                0.26|                0.66|    0.11616596078044727|\n",
      "|      107|                0.45|                0.85|    0.11597417369783877|\n",
      "|      146|                 0.5|                 0.9|    0.11488129439634706|\n",
      "|      103|                0.56|                0.96|    0.11617507884178278|\n",
      "|      139|                0.51|                0.91|    0.11519660023052102|\n",
      "|      138|                0.24|                0.64|     0.1155955860444133|\n",
      "|      114|                0.33|                0.73|    0.11510268816097273|\n",
      "|      115|                0.44|                0.84|    0.11569664615014985|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) \\\n",
    "            FROM utilization \\\n",
    "            GROUP BY server_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "58deb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries analysis with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b446915",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window = spark.sql('SELECT event_datetime, server_id, cpu_utilization, \\\n",
    "                        avg(cpu_utilization) OVER (PARTITION BY server_id) avg_server_util \\\n",
    "                        FROM utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9512ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:34|      112|           0.71|0.7153870000000067|\n",
      "|03/05/2019 08:11:34|      112|           0.78|0.7153870000000067|\n",
      "|03/05/2019 08:16:34|      112|           0.87|0.7153870000000067|\n",
      "|03/05/2019 08:21:34|      112|           0.82|0.7153870000000067|\n",
      "|03/05/2019 08:26:34|      112|           0.62|0.7153870000000067|\n",
      "|03/05/2019 08:31:34|      112|            0.9|0.7153870000000067|\n",
      "|03/05/2019 08:36:34|      112|           0.89|0.7153870000000067|\n",
      "|03/05/2019 08:41:34|      112|           0.81|0.7153870000000067|\n",
      "|03/05/2019 08:46:34|      112|           0.88|0.7153870000000067|\n",
      "|03/05/2019 08:51:34|      112|           0.89|0.7153870000000067|\n",
      "|03/05/2019 08:56:34|      112|           0.84|0.7153870000000067|\n",
      "|03/05/2019 09:01:34|      112|           0.71|0.7153870000000067|\n",
      "|03/05/2019 09:06:34|      112|           0.85|0.7153870000000067|\n",
      "|03/05/2019 09:11:34|      112|           0.72|0.7153870000000067|\n",
      "|03/05/2019 09:16:34|      112|           0.54|0.7153870000000067|\n",
      "|03/05/2019 09:21:34|      112|           0.58|0.7153870000000067|\n",
      "|03/05/2019 09:26:34|      112|           0.73|0.7153870000000067|\n",
      "|03/05/2019 09:31:34|      112|           0.86|0.7153870000000067|\n",
      "|03/05/2019 09:36:34|      112|           0.63|0.7153870000000067|\n",
      "|03/05/2019 09:41:34|      112|           0.75|0.7153870000000067|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_window.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c3b387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window2 = spark.sql('SELECT event_datetime, server_id, cpu_utilization, \\\n",
    "                        avg(cpu_utilization) OVER (PARTITION BY server_id) avg_server_util, \\\n",
    "                        cpu_utilization - avg(cpu_utilization) OVER (PARTITION BY server_id) delta_server_util \\\n",
    "                        FROM utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "26c66a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|   delta_server_util|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|03/05/2019 08:06:34|      112|           0.71|0.7153870000000067|-0.00538700000000...|\n",
      "|03/05/2019 08:11:34|      112|           0.78|0.7153870000000067| 0.06461299999999337|\n",
      "|03/05/2019 08:16:34|      112|           0.87|0.7153870000000067| 0.15461299999999334|\n",
      "|03/05/2019 08:21:34|      112|           0.82|0.7153870000000067|  0.1046129999999933|\n",
      "|03/05/2019 08:26:34|      112|           0.62|0.7153870000000067|-0.09538700000000666|\n",
      "|03/05/2019 08:31:34|      112|            0.9|0.7153870000000067| 0.18461299999999337|\n",
      "|03/05/2019 08:36:34|      112|           0.89|0.7153870000000067| 0.17461299999999336|\n",
      "|03/05/2019 08:41:34|      112|           0.81|0.7153870000000067|  0.0946129999999934|\n",
      "|03/05/2019 08:46:34|      112|           0.88|0.7153870000000067| 0.16461299999999335|\n",
      "|03/05/2019 08:51:34|      112|           0.89|0.7153870000000067| 0.17461299999999336|\n",
      "|03/05/2019 08:56:34|      112|           0.84|0.7153870000000067| 0.12461299999999331|\n",
      "|03/05/2019 09:01:34|      112|           0.71|0.7153870000000067|-0.00538700000000...|\n",
      "|03/05/2019 09:06:34|      112|           0.85|0.7153870000000067| 0.13461299999999332|\n",
      "|03/05/2019 09:11:34|      112|           0.72|0.7153870000000067|0.004612999999993317|\n",
      "|03/05/2019 09:16:34|      112|           0.54|0.7153870000000067|-0.17538700000000662|\n",
      "|03/05/2019 09:21:34|      112|           0.58|0.7153870000000067| -0.1353870000000067|\n",
      "|03/05/2019 09:26:34|      112|           0.73|0.7153870000000067|0.014612999999993326|\n",
      "|03/05/2019 09:31:34|      112|           0.86|0.7153870000000067| 0.14461299999999333|\n",
      "|03/05/2019 09:36:34|      112|           0.63|0.7153870000000067|-0.08538700000000665|\n",
      "|03/05/2019 09:41:34|      112|           0.75|0.7153870000000067|0.034612999999993344|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_window2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "afbae234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window3 = spark.sql('SELECT event_datetime, server_id, cpu_utilization, \\\n",
    "                        avg(cpu_utilization) over (PARTITION BY server_id ORDER BY event_datetime \\\n",
    "                                             ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) avg_server_util \\\n",
    "                        FROM utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c12cb03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:34|      112|           0.71|             0.745|\n",
      "|03/05/2019 08:11:34|      112|           0.78|0.7866666666666666|\n",
      "|03/05/2019 08:16:34|      112|           0.87|0.8233333333333333|\n",
      "|03/05/2019 08:21:34|      112|           0.82|              0.77|\n",
      "|03/05/2019 08:26:34|      112|           0.62|0.7799999999999999|\n",
      "|03/05/2019 08:31:34|      112|            0.9|0.8033333333333333|\n",
      "|03/05/2019 08:36:34|      112|           0.89|0.8666666666666667|\n",
      "|03/05/2019 08:41:34|      112|           0.81|              0.86|\n",
      "|03/05/2019 08:46:34|      112|           0.88|              0.86|\n",
      "|03/05/2019 08:51:34|      112|           0.89|              0.87|\n",
      "|03/05/2019 08:56:34|      112|           0.84|0.8133333333333334|\n",
      "|03/05/2019 09:01:34|      112|           0.71|0.7999999999999999|\n",
      "|03/05/2019 09:06:34|      112|           0.85|0.7600000000000001|\n",
      "|03/05/2019 09:11:34|      112|           0.72|0.7033333333333333|\n",
      "|03/05/2019 09:16:34|      112|           0.54|0.6133333333333333|\n",
      "|03/05/2019 09:21:34|      112|           0.58|0.6166666666666667|\n",
      "|03/05/2019 09:26:34|      112|           0.73|0.7233333333333333|\n",
      "|03/05/2019 09:31:34|      112|           0.86|0.7399999999999999|\n",
      "|03/05/2019 09:36:34|      112|           0.63|0.7466666666666667|\n",
      "|03/05/2019 09:41:34|      112|           0.75|0.6999999999999998|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_window3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5391f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0877c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "189a8459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d30380b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"cpu_utilization\", \"free_memory\", \"session_count\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "34f77acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcluster_df = vectorAssembler.transform(df_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bdf4c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+----------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|        features|\n",
      "+---------------+-------------------+-----------+---------+-------------+----------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|[0.57,0.51,47.0]|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|[0.47,0.62,43.0]|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|[0.56,0.57,62.0]|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|[0.57,0.56,50.0]|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|[0.35,0.46,43.0]|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|[0.41,0.58,48.0]|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|[0.57,0.35,58.0]|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58| [0.41,0.4,58.0]|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|[0.53,0.35,62.0]|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45| [0.51,0.6,45.0]|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|[0.32,0.37,47.0]|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|[0.62,0.59,60.0]|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|[0.66,0.72,57.0]|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|[0.54,0.54,44.0]|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47| [0.29,0.4,47.0]|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|[0.43,0.68,66.0]|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|[0.49,0.66,65.0]|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|[0.64,0.55,66.0]|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42| [0.42,0.6,42.0]|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|[0.55,0.59,63.0]|\n",
      "+---------------+-------------------+-----------+---------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vcluster_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8c264611",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(3)\n",
    "kmeans = kmeans.setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0b52df8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/24 22:51:14 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/08/24 22:51:14 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "kmodel = kmeans.fit(vcluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0a9c0885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.62881549,  0.37094643, 70.43030159]),\n",
       " array([ 0.52047775,  0.47836303, 51.79927162]),\n",
       " array([ 0.71931575,  0.28104316, 88.23965784])]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e9629ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0d162689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c266870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+--------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|features|\n",
      "+---------------+-------------------+-----------+---------+-------------+--------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|  [0.57]|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|  [0.47]|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|  [0.56]|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|  [0.57]|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|  [0.35]|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|  [0.41]|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|  [0.57]|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|  [0.41]|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|  [0.53]|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|  [0.51]|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|  [0.32]|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|  [0.62]|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|  [0.66]|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|  [0.54]|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|  [0.29]|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|  [0.43]|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|  [0.49]|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|  [0.64]|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|  [0.42]|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|  [0.55]|\n",
      "+---------------+-------------------+-----------+---------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"cpu_utilization\"], outputCol=\"features\")\n",
    "df_vutil = vectorAssembler.transform(df_util)\n",
    "df_vutil.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "66ed52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\",labelCol=\"session_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "56f5d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/24 22:53:41 WARN Instrumentation: [8adeb0dd] regParam is zero, which might cause numerical instability and overfitting.\n",
      "21/08/24 22:53:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "21/08/24 22:53:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lrModel = lr.fit(df_vutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "77c468e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([47.024])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "aa77e290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.416951035523546"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "94eefa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.837990225931746"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2673a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
